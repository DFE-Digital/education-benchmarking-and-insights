{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde75f1010d72b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:09.046979Z",
     "start_time": "2024-06-12T22:15:09.043820Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys  \n",
    "\n",
    "# Get my_package directory path from Notebook\n",
    "parent_dir = str(Path().resolve().parents[0])\n",
    "print(parent_dir)\n",
    "# Add to sys.path\n",
    "\n",
    "path_set = set(sys.path)\n",
    "if parent_dir not in path_set:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067c2e8c15b53c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# VMFI Data processing pipeline\n",
    "\n",
    "This workbook aims to emulate the current data processing pipeline that occurs in VMFI pipeline. The logic and processing is largely based on the following document [Insights data portal - Data sources and sql analysis](https://educationgovuk.sharepoint.com.mcas.ms/:w:/r/sites/VMFI/_layouts/15/Doc.aspx?sourcedoc=%7B38C1DC37-7CDB-48B8-9E22-284F4F311C0B%7D&file=1.%20Insights%20portal%20-%20data%20sources%20and%20sql%20analysis%20v010%20-%20Copy.docx&action=default&mobileredirect=true) and will stay true to this document even if the existing stored procedures are doing something different. This will form the basis of a gap analysis going forward. \n",
    "\n",
    "All data loaded in the following workbook comes from the set of CSV files in the `data` folder alongside this workbook. These datasets are for the most part from the list at the start of the linked document. However, because there is additional standing data required to fully implement the pipeline then this data has been exported from the development VMFI pipeline database. These files are currently: \n",
    "\n",
    "| File name | DB Table |\n",
    "|:----------|----------|\n",
    "|standing_data_cdc.csv | standing_data.cdc |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a62f29a05a0236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:09.749213Z",
     "start_time": "2024-06-12T22:15:09.154539Z"
    }
   },
   "outputs": [],
   "source": [
    "import src.pipeline.pre_processing as pre_processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:09.754367Z",
     "start_time": "2024-06-12T22:15:09.752282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create and clean directory\n",
    "from pathlib import Path\n",
    "Path(\"output/pre-processing\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# files = glob.glob(\"output/pre-processing/*\")\n",
    "# for f in files:\n",
    "#     os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed44fd15f640100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:09.756476Z",
     "start_time": "2024-06-12T22:15:09.754973Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "current_year = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96380a5227c987",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## CDC data load and preparation\n",
    "\n",
    "School buildings condition dataset. Based on the surveys performed throughout 2018-2019.\n",
    "\n",
    "The data in the file `data/standing_data_cdc.csv` is just an export of the data in `standing_data.cdc` table. Without the Year and Import ID fields. In future this will likely have to be read directly from the source database as per [this document.](https://educationgovuk.sharepoint.com.mcas.ms/:w:/r/sites/VMFI/_layouts/15/Doc.aspx?sourcedoc=%7B38C1DC37-7CDB-48B8-9E22-284F4F311C0B%7D&file=1.%20Insights%20portal%20-%20data%20sources%20and%20sql%20analysis%20v010%20-%20Copy.docx&action=default&mobileredirect=true) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563c9b9647d7005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:09.886203Z",
     "start_time": "2024-06-12T22:15:09.758155Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cdc = pre_processing.prepare_cdc_data('data/cdc.csv', current_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab167f20fdbd03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:09.894168Z",
     "start_time": "2024-06-12T22:15:09.886940Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#cdc.to_csv('output/pre-processing/cdc.csv')\n",
    "cdc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a30c5a4a9b466",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## School Census data load\n",
    "\n",
    "*Pupil Census* - DfE data collection providing information about school and pupil characteristics, for example percentage of pupils claiming free school`z meals, or having English as their second language. \n",
    "\n",
    "*Workforce census* - Single reference for all school workforce statistics based on staff working in publicly funded schools in England.\n",
    "\n",
    "The following code loads both the workforce and pupil census data and preforms an `inner` join by URN on the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d081b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:15.557331Z",
     "start_time": "2024-06-12T22:15:09.895262Z"
    }
   },
   "outputs": [],
   "source": [
    "census = pre_processing.prepare_census_data('data/census_workforce.xlsx', 'data/census_pupils.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d07eae73e8bba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:15.595411Z",
     "start_time": "2024-06-12T22:15:15.557928Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#census.to_csv('output/pre-processing/census.csv')\n",
    "census"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83d7512643b7a1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Special Education Needs (SEN) data load and preparation\n",
    "\n",
    "Special educational needs dataset. Contains information about the number of pupils, who require various SEN provisions. This loads the `SEN` data, which originates from [here](https://explore-education-statistics.service.gov.uk/find-statistics/special-educational-needs-in-england#dataDownloads-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a164f2280c8e888",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:15.714581Z",
     "start_time": "2024-06-12T22:15:15.596247Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sen = pre_processing.prepare_sen_data('data/sen.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cfde44fd23bbb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:15.723991Z",
     "start_time": "2024-06-12T22:15:15.715848Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#sen.to_csv(\"output/pre-processing/sen.csv\")\n",
    "sen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714b86a",
   "metadata": {},
   "source": [
    "## KS2 and KS4 processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca34e5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:36.141662Z",
     "start_time": "2024-06-12T22:15:15.726942Z"
    }
   },
   "outputs": [],
   "source": [
    "ks2 = pre_processing.prepare_ks2_data('data/ks2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89839a1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:36.146703Z",
     "start_time": "2024-06-12T22:15:36.142558Z"
    }
   },
   "outputs": [],
   "source": [
    "#ks2.to_csv('output/pre-processing/ks2.csv')\n",
    "ks2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6323c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:48.773012Z",
     "start_time": "2024-06-12T22:15:36.147331Z"
    }
   },
   "outputs": [],
   "source": [
    "ks4 = pre_processing.prepare_ks4_data('data/ks4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bae7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:48.778955Z",
     "start_time": "2024-06-12T22:15:48.773714Z"
    }
   },
   "outputs": [],
   "source": [
    "#ks4.to_csv('output/pre-processing/ks4.csv')\n",
    "ks4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3570cf02009cb5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## AR Data load and preparation\n",
    "\n",
    "This loads the Annual accounts return dataset and the corresponding mapping file. This extract only contains benchmarking section, which consists of submissions of costs, income, and balances of individual academies.\n",
    "\n",
    "The mapping file, contains the mapping from AR4 cell references to cost categories and descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb8252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:54.873965Z",
     "start_time": "2024-06-12T22:15:48.779703Z"
    }
   },
   "outputs": [],
   "source": [
    "academy_ar = pre_processing.prepare_aar_data('data/academy_ar.xlsx')\n",
    "central_services = pre_processing.prepare_central_services_data('data/academy_ar.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa06db2e9b4b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:54.889823Z",
     "start_time": "2024-06-12T22:15:54.874736Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#academy_ar.to_csv('output/pre-processing/academy_ar.csv')\n",
    "academy_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ef214422f8a44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:54.903363Z",
     "start_time": "2024-06-12T22:15:54.890507Z"
    }
   },
   "outputs": [],
   "source": [
    "central_services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26320ad386f89f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Create a summary table for the AR stance of each distinct academy in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320a9861dd3dc65",
   "metadata": {},
   "source": [
    "Now compute the trust financial position in the same manor as the individual academy position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b541a3aa8441b1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Academy and maintained schools data load and preparation\n",
    "\n",
    "This reads the main GIAS data (edubasealldataYYYYMMDD file) and the associated links file (links_edubasealldataYYYYMMDD file). This is taken from the [GIAS Service](https://get-information-schools.service.gov.uk/help)\n",
    "\n",
    "Other columns are tidied up by asserting the correct type for that column. This is tidying phase is largly because on load integer columns will be inferred to be a float as opposed to an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b28e64cbeba74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:56.232034Z",
     "start_time": "2024-06-12T22:15:54.904330Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "schools = pre_processing.prepare_schools_data('data/gias.csv','data/gias_links.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab1312a3261637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:56.273211Z",
     "start_time": "2024-06-12T22:15:56.232784Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#schools.to_csv('output/pre-processing/schools.csv')\n",
    "schools.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5843bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:56.413294Z",
     "start_time": "2024-06-12T22:15:56.274186Z"
    }
   },
   "outputs": [],
   "source": [
    "cfo = pre_processing.build_cfo_data('data/cfo.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a4b68ee88c7c1c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Merge required GIAS, census, sen, cdc, PFI, and arr data with the base academy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d591f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.pipeline.input_schemas as input_schemas\n",
    "import src.pipeline.mappings as mappings\n",
    "import src.pipeline.config as config\n",
    "import datetime\n",
    "\n",
    "\n",
    "def build_academy_data(\n",
    "    academy_data_path,\n",
    "    links_data_path,\n",
    "    year,\n",
    "    schools,\n",
    "    census,\n",
    "    sen,\n",
    "    cdc,\n",
    "    aar,\n",
    "    ks2,\n",
    "    ks4,\n",
    "    cfo,\n",
    "    central_services,\n",
    "):\n",
    "    accounts_return_period_start_date = datetime.date(year - 1, 9, 10)\n",
    "    academy_year_start_date = datetime.date(year - 1, 9, 1)\n",
    "    academy_year_end_date = datetime.date(year, 8, 30)\n",
    "    print('here')\n",
    "    academies_list = pd.read_csv(\n",
    "        academy_data_path,\n",
    "        encoding=\"utf8\",\n",
    "        usecols=input_schemas.academy_master_list.keys(),\n",
    "    )\n",
    "    print('here')\n",
    "    academies_list.replace(to_replace={'DNS':np.nan,'n/a':np.nan}, inplace=True)\n",
    "    academies_list = academies_list.astype(\n",
    "        input_schemas.academy_master_list\n",
    "    ).set_index(input_schemas.academy_master_list_index_col).rename(columns={\"UKPRN\": \"Academy UKPRN\"})\n",
    "\n",
    "    print('here')\n",
    "    group_links = pd.read_csv(\n",
    "        links_data_path,\n",
    "        encoding=\"cp1252\",\n",
    "        index_col=input_schemas.groups_index_col,\n",
    "        usecols=input_schemas.groups.keys(),\n",
    "        dtype=input_schemas.groups,\n",
    "    )[[\"Group Type\", \"Group UID\"]]\n",
    "    group_links = group_links[\n",
    "        group_links[\"Group Type\"].isin(\n",
    "            [\"Single-academy trust\", \"Multi-academy trust\", \"Trust\"]\n",
    "        )\n",
    "    ]\n",
    "    print('here')\n",
    "    # remove transitioned schools from academies_list\n",
    "    mask = (\n",
    "        academies_list.index.duplicated(keep=False) & ~academies_list[\"Valid to\"].isna()\n",
    "    )\n",
    "    print('here')\n",
    "    academies_list = academies_list[~mask]\n",
    "    academies_base = academies_list.merge(\n",
    "        schools.reset_index(), left_index=True, right_on=\"LA Establishment Number\"\n",
    "    )\n",
    "    print('here')\n",
    "    academies = (\n",
    "        academies_base.merge(census, on=\"URN\", how=\"left\")\n",
    "        .merge(sen, on=\"URN\", how=\"left\")\n",
    "        .merge(cdc, on=\"URN\", how=\"left\")\n",
    "        .merge(aar, on=\"URN\", how=\"left\")\n",
    "        .merge(ks2, on=\"URN\", how=\"left\")\n",
    "        .merge(ks4, on=\"URN\", how=\"left\")\n",
    "        .merge(group_links, on=\"URN\", how=\"inner\")\n",
    "        .merge(cfo, on=\"URN\", how=\"left\")\n",
    "    )\n",
    "    print('here')\n",
    "    academies[\"Total Internal Floor Area\"] = academies[\n",
    "        \"Total Internal Floor Area\"\n",
    "    ].fillna(academies[\"Total Internal Floor Area\"].median())\n",
    "    academies[\"Overall Phase\"] = academies.apply(\n",
    "        lambda df: mappings.map_academy_phase_type(\n",
    "            df[\"TypeOfEstablishment (code)\"], df[\"Type of Provision - Phase\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    academies[\"Status\"] = academies.apply(\n",
    "        lambda df: mappings.map_academy_status(\n",
    "            pd.to_datetime(df[\"Date joined or opened if in period\"]),\n",
    "            pd.to_datetime(df[\"Date left or closed if in period\"]),\n",
    "            pd.to_datetime(df[\"Valid to\"]),\n",
    "            pd.to_datetime(df[\"OpenDate\"]),\n",
    "            pd.to_datetime(df[\"CloseDate\"]),\n",
    "            pd.to_datetime(accounts_return_period_start_date),\n",
    "            pd.to_datetime(academy_year_start_date),\n",
    "            pd.to_datetime(academy_year_end_date),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    academies[\"Period covered by return\"] = academies.apply(\n",
    "        lambda df: mappings.map_academy_period_return(\n",
    "            pd.to_datetime(df[\"Date joined or opened if in period\"]),\n",
    "            pd.to_datetime(df[\"Date left or closed if in period\"]),\n",
    "            pd.to_datetime(academy_year_start_date),\n",
    "            pd.to_datetime(academy_year_end_date),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    academies[\"SchoolPhaseType\"] = academies.apply(\n",
    "        lambda df: mappings.map_school_phase_type(\n",
    "            df[\"TypeOfEstablishment (code)\"], df[\"Type of Provision - Phase\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    academies[\"Finance Type\"] = \"Academy\"\n",
    "\n",
    "    academies.rename(\n",
    "        columns={\n",
    "            \"URN_x\":\"URN\",\n",
    "            \"UKPRN_x\": \"UKPRN\",\n",
    "            \"LA (code)\": \"LA Code\",\n",
    "            \"LA (name)\": \"LA Name\",\n",
    "            \"Academy Trust Name\": \"Trust Name\",\n",
    "            \"Academy UKPRN\": \"Trust UKPRN\",\n",
    "        }\n",
    "        | config.income_category_map[\"academies\"]\n",
    "        | config.cost_category_map[\"academies\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    academies[\"OfstedLastInsp\"] = pd.to_datetime(\n",
    "        academies[\"OfstedLastInsp\"], dayfirst=True\n",
    "    )\n",
    "    academies[\"London Weighting\"] = academies[\"London Weighting\"].fillna(\"Neither\")\n",
    "    academies[\"Email\"] = \"\"\n",
    "    academies[\"HeadEmail\"] = \"\"\n",
    "    for category in config.rag_category_settings.keys():\n",
    "        basis_data = academies[\n",
    "            (\n",
    "                \"Number of pupils\"\n",
    "                if config.rag_category_settings[category][\"type\"] == \"Pupil\"\n",
    "                else \"Total Internal Floor Area\"\n",
    "            )\n",
    "        ]\n",
    "        academies = mappings.map_cost_series(category, academies, basis_data)\n",
    "\n",
    "    academies[\"Catering staff and supplies_Net Costs\"] = (\n",
    "        academies[\"Income_Catering services\"]\n",
    "        + academies[\"Catering staff and supplies_Total\"]\n",
    "    )\n",
    "\n",
    "    trust_basis_data = (\n",
    "        academies.sort_values(by=\"Trust UPIN\")[\n",
    "            [\"Number of pupils\", \"Trust UPIN\", \"Total Internal Floor Area\"]\n",
    "        ]\n",
    "        .groupby([\"Trust UPIN\"])\n",
    "        .sum()\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"Number of pupils\": \"Total pupils in trust\",\n",
    "                \"Total Internal Floor Area\": \"Total Internal Floor Area in trust\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    central_services = central_services.merge(\n",
    "        trust_basis_data, on=\"Trust UPIN\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Apportion central services data based on the given basis of the cost category\n",
    "    for category in config.rag_category_settings.keys():\n",
    "        cs_basis_data = central_services[\n",
    "            (\n",
    "                \"Total pupils in trust\"\n",
    "                if config.rag_category_settings[category][\"type\"] == \"Pupil\"\n",
    "                else \"Total Internal Floor Area in trust\"\n",
    "            )\n",
    "        ]\n",
    "        central_services = mappings.map_cost_series(\n",
    "            category, central_services, cs_basis_data\n",
    "        )\n",
    "\n",
    "    central_services[\"Catering staff and supplies_Net Costs\"] = (\n",
    "        central_services[\"Income_Catering services\"]\n",
    "        + central_services[\"Catering staff and supplies_Total\"]\n",
    "    )\n",
    "\n",
    "    # Apportion the central services income fields\n",
    "    income_cols = central_services.columns[\n",
    "        central_services.columns.str.startswith(\"Income_\")\n",
    "    ].values.tolist()\n",
    "\n",
    "    for income_col in income_cols:\n",
    "        central_services[income_col] = (\n",
    "            central_services[income_col] / central_services[\"Total pupils in trust\"]\n",
    "        )\n",
    "\n",
    "    academies = academies.merge(\n",
    "        central_services, on=\"Trust UPIN\", how=\"left\", suffixes=(\"\", \"_CS\")\n",
    "    )\n",
    "\n",
    "    return academies.set_index(\"URN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b5d9b44e7947e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:58.955461Z",
     "start_time": "2024-06-12T22:15:56.414398Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "academies = build_academy_data('data/academy_master_list.csv', 'data/gias_all_links.csv',\n",
    "                                              current_year, schools, census, sen, cdc, \n",
    "                                              academy_ar, ks2, ks4, cfo, central_services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b18891fd8d969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:15:58.987195Z",
     "start_time": "2024-06-12T22:15:58.956163Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#academies.to_csv('output/pre-processing/academies.csv')\n",
    "academies.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97961d9851b09fc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Merge required census and cdc data to the maintained schools data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_federations_data(links_data_path, maintained_schools):\n",
    "    group_links = pd.read_csv(\n",
    "        links_data_path,\n",
    "        encoding=\"unicode-escape\",\n",
    "        index_col=input_schemas.groups_index_col,\n",
    "        usecols=input_schemas.groups.keys(),\n",
    "        dtype=input_schemas.groups,\n",
    "    )\n",
    "\n",
    "    federations = maintained_schools[[\"URN\", \"LAEstab\"]][\n",
    "        maintained_schools[\"Federation\"] == \"Lead school\"\n",
    "    ].copy()\n",
    "\n",
    "    # join\n",
    "    federations = federations.join(\n",
    "        group_links[[\"Group Name\", \"Group UID\", \"Closed Date\"]], on=\"URN\"\n",
    "    )\n",
    "\n",
    "    # remove federations with an associated closed date\n",
    "    federations = federations.loc[federations[\"Closed Date\"].isna()]\n",
    "\n",
    "    # federations with a UID listed in the GIAS groups data are referred to as \"Hard\" federations\n",
    "    # while federations not listed in GIAS are referred to as \"Soft\" federations.\n",
    "    # Soft federation UIDs are a combination of their URN and LAEstab codes.\n",
    "\n",
    "    # create mask for soft federations\n",
    "    mask = federations[\"Group UID\"].isna()\n",
    "\n",
    "    hard_federations = federations.loc[~mask].copy()\n",
    "    soft_federations = federations.loc[mask].copy()\n",
    "\n",
    "    # define members list for hard federations\n",
    "    group_links[\"Members\"] = group_links.index\n",
    "    hard_members = group_links[[\"Members\", \"Group UID\"]].groupby(\"Group UID\").agg(list)\n",
    "\n",
    "    hard_federations = hard_federations.join(hard_members, on=\"Group UID\")\n",
    "\n",
    "    # Rename columns\n",
    "    hard_federations.rename(\n",
    "        columns={\n",
    "            \"Group Name\": \"FederationName\",\n",
    "            \"Group UID\": \"FederationUid\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    # for the soft federations\n",
    "    soft_federations[\"Group UID\"] = soft_federations.index.astype(\n",
    "        str\n",
    "    ) + soft_federations[\"LAEstab\"].astype(str)\n",
    "\n",
    "    # Rename columns\n",
    "    soft_federations.rename(\n",
    "        columns={\n",
    "            \"Group Name\": \"FederationName\",\n",
    "            \"Group UID\": \"FederationUid\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return hard_federations, soft_federations\n",
    "\n",
    "\n",
    "def build_maintained_school_data(\n",
    "    maintained_schools_data_path,\n",
    "    links_data_path,\n",
    "    year,\n",
    "    schools,\n",
    "    census,\n",
    "    sen,\n",
    "    cdc,\n",
    "    ks2,\n",
    "    ks4,\n",
    "):\n",
    "    maintained_schools_year_start_date = datetime.date(year - 1, 4, 1)\n",
    "    maintained_schools_year_end_date = datetime.date(year, 3, 31)\n",
    "\n",
    "    maintained_schools_list = pd.read_csv(\n",
    "        maintained_schools_data_path,\n",
    "        encoding=\"unicode-escape\",\n",
    "        usecols=input_schemas.maintained_schools_master_list.keys(),\n",
    "    )\n",
    "    # remove any DNS schools\n",
    "    mask = ((maintained_schools_list['Did Not Supply flag'] == '0').values \n",
    "            | (maintained_schools_list['Did Not Supply flag'] == 0).values)\n",
    "    maintained_schools_list = maintained_schools_list.loc[mask]\n",
    "    maintained_schools_list.replace({'DNS':np.nan}, inplace=True)\n",
    "\n",
    "    maintained_schools_list = maintained_schools_list.astype(\n",
    "        input_schemas.maintained_schools_master_list\n",
    "    ).set_index(input_schemas.maintained_schools_master_list_index_col)\n",
    "    \n",
    "    \n",
    "    maintained_schools = maintained_schools_list.merge(\n",
    "        schools.reset_index(), left_index=True, right_on=\"URN\"\n",
    "    )\n",
    "\n",
    "    maintained_schools = (\n",
    "        maintained_schools.merge(sen, on=\"URN\", how=\"left\")\n",
    "        .merge(census, on=\"URN\", how=\"left\")\n",
    "        .merge(cdc, on=\"URN\", how=\"left\")\n",
    "        .merge(ks2, on=\"URN\", how=\"left\")\n",
    "        .merge(ks4, on=\"URN\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"PFI\"] = maintained_schools[\"PFI\"].map(\n",
    "        lambda x: \"PFI school\" if x == \"Y\" else \"Non-PFI school\"\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"Is PFI\"] = maintained_schools[\"PFI\"].map(\n",
    "        lambda x: x == \"PFI school\"\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"Status\"] = maintained_schools.apply(\n",
    "        lambda df: mappings.map_maintained_school_status(\n",
    "            df[\"OpenDate\"],\n",
    "            df[\"CloseDate\"],\n",
    "            df[\"Period covered by return (months)\"],\n",
    "            pd.to_datetime(maintained_schools_year_start_date),\n",
    "            pd.to_datetime(maintained_schools_year_end_date),\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"In year balance\"] = (\n",
    "        maintained_schools[\"Total Income   I01 to I18\"]\n",
    "        - maintained_schools[\"Total Expenditure  E01 to E32\"]\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"Financial Position\"] = maintained_schools[\n",
    "        \"In year balance\"\n",
    "    ].map(mappings.map_is_surplus_deficit)\n",
    "\n",
    "    maintained_schools[\"SchoolPhaseType\"] = maintained_schools.apply(\n",
    "        lambda df: mappings.map_school_phase_type(\n",
    "            df[\"TypeOfEstablishment (code)\"], df[\"Overall Phase\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"Partial Years Present\"] = maintained_schools[\n",
    "        \"Period covered by return (months)\"\n",
    "    ].map(lambda x: x != 12)\n",
    "\n",
    "    maintained_schools[\"Did Not Submit\"] = maintained_schools[\n",
    "        \"Did Not Supply flag\"\n",
    "    ].map(lambda x: x == 1)\n",
    "\n",
    "    maintained_schools[\"Finance Type\"] = \"Maintained\"\n",
    "\n",
    "    maintained_schools[\"Email\"] = \"\"\n",
    "    maintained_schools[\"HeadEmail\"] = \"\"\n",
    "    maintained_schools[\"Trust Name\"] = None\n",
    "    maintained_schools[\"OfstedLastInsp\"] = pd.to_datetime(\n",
    "        maintained_schools[\"OfstedLastInsp\"], dayfirst=True\n",
    "    )\n",
    "    maintained_schools[\"London Weighting\"] = maintained_schools[\n",
    "        \"London Weighting\"\n",
    "    ].fillna(\"Neither\")\n",
    "\n",
    "    maintained_schools[\"Income_Direct grants\"] = (\n",
    "        maintained_schools[\"I01  Funds delegated by the LA\"]\n",
    "        + maintained_schools[\"I02  Funding for 6th form students\"]\n",
    "        + maintained_schools[\"I06  Other government grants\"]\n",
    "        + maintained_schools[\"I07  Other grants and payments\"]\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"Income_Targeted grants\"] = (\n",
    "        maintained_schools[\"I04  Funding for minority ethnic pupils\"]\n",
    "        + maintained_schools[\"I03  SEN funding\"]\n",
    "        + maintained_schools[\"I05  Pupil Premium\"]\n",
    "        + maintained_schools[\n",
    "            \"I15  Pupil focussed extended school funding and   or grants\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"Income_Total self generated funding\"] = (\n",
    "        maintained_schools[\"I08  Income from facilities and services\"]\n",
    "        + maintained_schools[\"I09  Income from catering\"]\n",
    "        + maintained_schools[\"I10  Receipts from supply teacher insurance claims\"]\n",
    "        + maintained_schools[\"I11  Receipts from other insurance claims\"]\n",
    "        + maintained_schools[\"I12  Income from contributions to visits etc \"]\n",
    "        + maintained_schools[\"I13  Donations and or private funds\"]\n",
    "        + maintained_schools[\"I17  Community focused school facilities income\"]\n",
    "    )\n",
    "\n",
    "    maintained_schools[\"Income_Community grants\"] = (\n",
    "        maintained_schools[\"I16  Community focussed school funding and   or grants\"]\n",
    "        + maintained_schools[\"I18  Additional grant for schools\"]\n",
    "    )\n",
    "\n",
    "    maintained_schools.rename(\n",
    "        columns={\"Period covered by return (months)\": \"Period covered by return\"}\n",
    "        | config.cost_category_map[\"maintained_schools\"]\n",
    "        | config.income_category_map[\"maintained_schools\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    for category in config.rag_category_settings.keys():\n",
    "        basis_data = maintained_schools[\n",
    "            (\n",
    "                \"Number of pupils\"\n",
    "                if config.rag_category_settings[category][\"type\"] == \"Pupil\"\n",
    "                else \"Total Internal Floor Area\"\n",
    "            )\n",
    "        ]\n",
    "        maintained_schools = mappings.map_cost_series(\n",
    "            category, maintained_schools, basis_data\n",
    "        )\n",
    "\n",
    "    maintained_schools[\"Catering staff and supplies_Net Costs\"] = (\n",
    "        maintained_schools[\"Income_Catering services\"]\n",
    "        + maintained_schools[\"Catering staff and supplies_Total\"]\n",
    "    )\n",
    "\n",
    "    maintained_schools = maintained_schools[maintained_schools.index.notnull()]\n",
    "\n",
    "    (hard_federations, soft_federations) = build_federations_data(\n",
    "        links_data_path, maintained_schools\n",
    "    )\n",
    "\n",
    "    # Applying federation mappings\n",
    "    list_of_laestabs = maintained_schools[\"LAEstab\"][\n",
    "        maintained_schools[\"Lead school in federation\"] != \"0\"\n",
    "    ]\n",
    "    list_of_urns = maintained_schools.index[\n",
    "        maintained_schools[\"Lead school in federation\"] != \"0\"\n",
    "    ]\n",
    "    lae_ukprn = dict(zip(list_of_laestabs, list_of_urns))\n",
    "\n",
    "    maintained_schools[\"Federation Lead School URN\"] = maintained_schools[\n",
    "        \"Lead school in federation\"\n",
    "    ].map(lae_ukprn)\n",
    "\n",
    "    maintained_schools = pd.merge(\n",
    "        maintained_schools,\n",
    "        hard_federations[[\"FederationName\"]],\n",
    "        how=\"left\",\n",
    "        left_index=True,\n",
    "        right_index=True,\n",
    "    )\n",
    "    maintained_schools.rename(\n",
    "        columns={\"FederationName\": \"Federation Name\"}, inplace=True\n",
    "    )\n",
    "    maintained_schools = maintained_schools[~maintained_schools.index.duplicated()]\n",
    "\n",
    "    return maintained_schools.set_index(\"URN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625f25c-3391-43ac-9cc2-c2a204c5663e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:16:00.025577Z",
     "start_time": "2024-06-12T22:15:58.987962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load raw list from CSV\n",
    "maintained_schools = pre_processing.build_maintained_school_data('data/maintained_schools_master_list.csv','data/gias_all_links.csv',current_year, schools, census, sen, cdc, ks2, ks4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f7539-929c-4add-aa04-de2e25437c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:16:01.104933Z",
     "start_time": "2024-06-12T22:16:00.026323Z"
    }
   },
   "outputs": [],
   "source": [
    "maintained_schools.to_csv('output/pre-processing/maintained_schools.csv')\n",
    "#maintained_schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ee73b7344621d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T22:16:01.165188Z",
     "start_time": "2024-06-12T22:16:01.105780Z"
    }
   },
   "outputs": [],
   "source": [
    "all_schools = pd.concat([academies,maintained_schools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d4c3be39d8e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_schools[all_schools[\"Is PFI\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429dff32",
   "metadata": {},
   "source": [
    "## Federation Capture\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c2fabd-3a66-4edc-9b77-b1bd549071d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(hard_federations, soft_federations) = pre_processing.build_federations_data('data/gias_all_links.csv', maintained_schools.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe0d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_federations.to_csv('output/pre-processing/hard_federations.csv')\n",
    "hard_federations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b96c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_federations.to_csv('output/pre-processing/soft_federations.csv')\n",
    "soft_federations[['LAEstab']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8849856",
   "metadata": {},
   "source": [
    "# Budget Forcast Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd92ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023\n",
    "\n",
    "bfr_cell_mapping_cols = {'EFALineNo':'Int64','balance_flag':'Int64'}\n",
    "\n",
    "bfr_sofa_cols = {'TrustUPIN':'Int64','CreatedBy':'string','Category':'string','Title':'string','EFALineNo':'Int64','Y1P1':'float','Y1P2':'float','Y2P1':'float','Y2P2':'float'}\n",
    "bfr_3y_cols = {'TrustUPIN':'Int64','EFALineNo':'Int64','Y2':'Int64','Y3':'Int64','Y4':'Int64'}\n",
    "\n",
    "\n",
    "def _calculate_metrics(bfr):\n",
    "    bfr_metrics = bfr[['TrustUPIN']].copy().set_index('TrustUPIN')\n",
    "    bfr_metrics['Revenue reserve as percentage of income'] =\\\n",
    "          round(bfr[bfr['Title']=='Revenue reserves'].set_index('TrustUPIN')[['Y1']]\n",
    "                /bfr[bfr['Title']=='Total income'].set_index('TrustUPIN')[['Y1']]*100,1)\n",
    "    bfr_metrics['Staff costs as percentage of income'] =\\\n",
    "          round(bfr[bfr['Title']=='Staff costs'].set_index('TrustUPIN')[['Y1']]\n",
    "                /bfr[bfr['Title']=='Total income'].set_index('TrustUPIN')[['Y1']]*100,1)\n",
    "    bfr_metrics['Expenditure as percentage of income'] =\\\n",
    "          round(bfr[bfr['Title']=='Total expenditure'].set_index('TrustUPIN')[['Y1']]\n",
    "                /bfr[bfr['Title']=='Total income'].set_index('TrustUPIN')[['Y1']]*100,1)\n",
    "    bfr_metrics['percent self-generated income'] =\\\n",
    "          round(bfr[bfr['Title']=='Self-generated income'].set_index('TrustUPIN')[['Y1']]/\n",
    "                (bfr[bfr['Title']=='Self-generated income'].set_index('TrustUPIN')[['Y1']] +\n",
    "                  bfr[bfr['Title']=='Grant funding'].set_index('TrustUPIN')[['Y1']])*100,0)\n",
    "    bfr_metrics['percent grant funding'] = 100 - bfr_metrics['percent self-generated income']\n",
    "    return bfr_metrics\n",
    "\n",
    "def _calculate_slopes(matrix):\n",
    "    x = np.array([1,2,3,4,5,6])\n",
    "    x_bar = 3.5\n",
    "    x_x_bar = x - x_bar\n",
    "    y_bar = np.mean(matrix, axis=1)\n",
    "    y_y_bar = matrix - np.vstack(y_bar)\n",
    "    slope_array = np.sum(x_x_bar*y_y_bar,axis=1)/np.sum(x_x_bar**2)\n",
    "    return slope_array\n",
    "\n",
    "def _assign_slope_flag(df):\n",
    "    percentile_10 = np.nanpercentile(df['slope'].values, 10)\n",
    "    percentile_90 = np.nanpercentile(df['slope'].values, 90)\n",
    "    df['slope_flag'] = 0\n",
    "    df.loc[df['slope'] < percentile_10, 'slope_flag'] = -1\n",
    "    df.loc[df['slope'] > percentile_90, 'slope_flag'] = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "def _slope_analysis(bfr_dataframe, academies_y2, academies_y1):\n",
    "\n",
    "    year_columns = ['Y-2','Y-1','Y1','Y2','Y3','Y4']\n",
    "    bfr_revenue_reserves = bfr_dataframe[bfr_dataframe['Title']=='Revenue reserves']\n",
    "    bfr_pupil_numbers = bfr_dataframe[bfr_dataframe['Title']=='Pupil numbers']\n",
    "\n",
    "    \n",
    "\n",
    "    # TODO need to add in historic data to this, filling in fake values for now\n",
    "    bfr_revenue_reserves = pd.merge(\n",
    "        bfr_revenue_reserves, \n",
    "        academies_y2[['Trust UPIN','Trust Balance']].rename(columns={\n",
    "            'Trust UPIN':'TrustUPIN',\n",
    "            'Trust Balance':'Y-2'\n",
    "            }).drop_duplicates(), how='left', on='TrustUPIN')\n",
    "    \n",
    "    bfr_revenue_reserves = pd.merge(\n",
    "        bfr_revenue_reserves, \n",
    "        academies_y1[['Trust UPIN','Trust Balance']].rename(columns={\n",
    "                'Trust UPIN':'TrustUPIN',\n",
    "                'Trust Balance':'Y-1'\n",
    "                }).drop_duplicates(), how='left', on='TrustUPIN')\n",
    "    \n",
    "    bfr_pupil_numbers = pd.merge(\n",
    "        bfr_pupil_numbers, \n",
    "        academies_y2[['Trust UPIN','Number of pupils']].rename(columns={\n",
    "            'Trust UPIN':'TrustUPIN',\n",
    "            'Number of pupils':'Y-2'\n",
    "            }).groupby('TrustUPIN').agg(sum), how='left', on='TrustUPIN')\n",
    "    \n",
    "    bfr_pupil_numbers = pd.merge(\n",
    "        bfr_pupil_numbers, \n",
    "        academies_y2[['Trust UPIN','Number of pupils']].rename(columns={\n",
    "            'Trust UPIN':'TrustUPIN',\n",
    "            'Number of pupils':'Y-1'\n",
    "            }).groupby('TrustUPIN').agg(sum), how='left', on='TrustUPIN')\n",
    "\n",
    "\n",
    "    # convert to matrix\n",
    "    matrix_revenue_reserves = bfr_revenue_reserves[year_columns].values.astype(float)\n",
    "    matrix_pupil_numbers = bfr_pupil_numbers[year_columns].values.astype(float)\n",
    "\n",
    "    matrix_revenue_reserves_per_pupil = matrix_revenue_reserves/matrix_pupil_numbers\n",
    "\n",
    "    # determine associated slopes\n",
    "    bfr_revenue_reserves['slope'] = _calculate_slopes(matrix_revenue_reserves)\n",
    "\n",
    "    bfr_revenue_reserves_per_pupil = bfr_revenue_reserves[['CreatedBy','Category','Title','EFALineNo']].copy()\n",
    "    bfr_revenue_reserves_per_pupil['slope'] = _calculate_slopes(matrix_revenue_reserves_per_pupil)\n",
    "    for i in range(len(year_columns)):\n",
    "        bfr_revenue_reserves_per_pupil[year_columns[i]] = matrix_revenue_reserves_per_pupil.T[i]\n",
    "\n",
    "\n",
    "    # flag top 10% and bottom 90% percent of slopes with -1 and 1 respectively\n",
    "    bfr_revenue_reserves = _assign_slope_flag(bfr_revenue_reserves)\n",
    "    bfr_revenue_reserves_per_pupil = _assign_slope_flag(bfr_revenue_reserves_per_pupil)\n",
    "\n",
    "    return bfr_revenue_reserves, bfr_revenue_reserves_per_pupil\n",
    "\n",
    "def _volatility_analysis(bfr):\n",
    "    bfr['volatility'] = (bfr['Trust Balance'] - bfr['Y1P2'])/abs(bfr['Trust Balance'])\n",
    "\n",
    "    volatility_conditions = [(bfr['volatility'] <= -0.05),\n",
    "                            (bfr['volatility'] <= 0.05),\n",
    "                            (bfr['volatility'] <= 0.1),\n",
    "                            (bfr['volatility'] > 0.1)]\n",
    "    volatility_messages = [\"AR below forecast\", \n",
    "                        \"stable forecast\", \n",
    "                        \"AR above forecast\", \n",
    "                        \"AR significantly above forecast\"]\n",
    "\n",
    "    bfr['volatility_status'] = np.select(volatility_conditions, volatility_messages, default='')\n",
    "    return bfr\n",
    "\n",
    "def build_bfr_data(bfr_sofa_data_path,bfr_3y_data_path, academies_y2, academies_y1, academies):\n",
    "\n",
    "    bfr_sofa = pd.read_csv(\n",
    "        bfr_sofa_data_path,\n",
    "        encoding='unicode-escape',\n",
    "        dtype=bfr_sofa_cols,\n",
    "        usecols=bfr_sofa_cols.keys(),\n",
    "    )\n",
    "\n",
    "    bfr_3y = pd.read_csv(\n",
    "        bfr_3y_data_path,\n",
    "        encoding='unicode-escape',\n",
    "        dtype=bfr_3y_cols,\n",
    "        usecols=bfr_3y_cols.keys(),\n",
    "    )    \n",
    "\n",
    "\n",
    "    # remove unused metrics\n",
    "    bfr_sofa = bfr_sofa[bfr_sofa['EFALineNo'].isin([298,430,335,380,211,220,199,200,205,210,999])]\n",
    "\n",
    "    self_gen_income = bfr_sofa[\n",
    "        bfr_sofa['EFALineNo'].isin([211,220])\n",
    "        ].groupby('TrustUPIN')[['Y1P1','Y1P2','Y2P1','Y2P2']].sum().reset_index()\n",
    "    self_gen_income['Title'] = 'Self-generated income'\n",
    "\n",
    "    grant_funding = bfr_sofa[\n",
    "        bfr_sofa['EFALineNo'].isin([199,200,205,210])\n",
    "        ].groupby('TrustUPIN')[['Y1P1','Y1P2','Y2P1','Y2P2']].sum().reset_index()\n",
    "    grant_funding['Title'] = 'Grant funding'\n",
    "\n",
    "    bfr_sofa = bfr_sofa[~bfr_sofa['EFALineNo'].isin([211,220,199,200,205,210])]\n",
    "    bfr_sofa = pd.concat([bfr_sofa, self_gen_income, grant_funding])\n",
    "    bfr_sofa['Title'].replace({\n",
    "        'Balance c/f to next period ':'Revenue reserves',\n",
    "        'Pupil numbers (actual and estimated)':'Pupil numbers',\n",
    "        'Total revenue expenditure':'Total expenditure',\n",
    "        'Total revenue income':'Total income','Total staff costs':'Staff costs'\n",
    "        }, inplace=True)\n",
    "    bfr_sofa['Y1'] = bfr_sofa['Y1P1'] + bfr_sofa['Y1P2']\n",
    "    bfr_sofa.drop_duplicates(inplace=True)\n",
    "    \n",
    "    bfr_3y['EFALineNo'].replace({2980:298,4300:430,3800:380,9000:999}, inplace=True)\n",
    "    bfr_3y = bfr_3y[bfr_3y['EFALineNo'].isin([298,430,335,380,999])]\n",
    "    bfr_3y.drop_duplicates(inplace=True)\n",
    "    \n",
    "\n",
    "    bfr = pd.merge(bfr_sofa, bfr_3y, how='left', on=('TrustUPIN','EFALineNo'))\n",
    "    \n",
    "    # get trust metrics\n",
    "    bfr_metrics = _calculate_metrics(bfr)\n",
    "    # Slope analysis\n",
    "    bfr_revenue_reserves, bfr_revenue_reserves_per_pupil = _slope_analysis(bfr, academies_y2, academies_y1)\n",
    "\n",
    "    # volatility analysis\n",
    "    bfr = pd.merge(bfr, academies[['Trust UPIN','Trust Balance']].rename(\n",
    "        columns={'Trust UPIN': 'TrustUPIN'}), how='left', on='TrustUPIN')\n",
    "    bfr = _volatility_analysis(bfr)\n",
    "    \n",
    "    bfr_metrics.drop_duplicates(inplace=True)\n",
    "    \n",
    "    use_columns = [\"Y-2\",\"Y-1\",\"Y1\",\"Y2\",\"Y3\",\"slope\",\"slope_flag\"]\n",
    "    \n",
    "    bfr_revenue_reserves.drop_duplicates(inplace=True)\n",
    "    bfr_revenue_reserves = bfr_revenue_reserves[use_columns]\n",
    "    bfr_revenue_reserves.rename(columns={\n",
    "        \"Y-2\":\"revenue_reserves_year_-2\",\n",
    "        \"Y-1\":\"revenue_reserves_year_-1\",\n",
    "        \"Y1\":\"revenue_reserves_year_0\",\n",
    "        \"Y2\":\"revenue_reserves_year_1\",\n",
    "        \"Y3\":\"revenue_reserves_year_2\",\n",
    "        \"slope\":\"revenue_reserves_slope\",\n",
    "        \"slope_flag\":\"revenue_reserves_slope_flag\"}, inplace=True)\n",
    "    \n",
    "    \n",
    "    bfr_revenue_reserves_per_pupil.drop_duplicates(inplace=True)\n",
    "    bfr_revenue_reserves_per_pupil = bfr_revenue_reserves_per_pupil[use_columns]\n",
    "    bfr_revenue_reserves_per_pupil.rename(columns={\n",
    "        \"Y-2\":\"revenue_reserves_year_per_pupil_-2\",\n",
    "        \"Y-1\":\"revenue_reserves_year_per_pupil_-1\",\n",
    "        \"Y1\":\"revenue_reserves_year_per_pupil_0\",\n",
    "        \"Y2\":\"revenue_reserves_year_per_pupil_1\",\n",
    "        \"Y3\":\"revenue_reserves_year_per_pupil_2\",\n",
    "        \"slope\":\"revenue_reserves_year_per_pupil_slope\",\n",
    "        \"slope_flag\":\"revenue_reserves_year_per_pupil_slope_flag\"}, inplace=True)\n",
    "    \n",
    "    bfr_metrics = pd.merge(bfr_metrics, bfr_revenue_reserves, left_index=True, right_index=True)\n",
    "    bfr_metrics = pd.merge(bfr_metrics, bfr_revenue_reserves_per_pupil, left_index=True, right_index=True)\n",
    "    return bfr_metrics, bfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfr_metrics, bfr = build_bfr_data('data/BFR_SOFA_raw.csv','data/BFR_3Y_raw.csv', academies.copy().reset_index(), academies.copy().reset_index(), academies.copy().reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3001591261b92",
   "metadata": {},
   "source": [
    "### Timing Keep at the bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd17dab96412d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Processing Time: {time.time() - start_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394ebe8",
   "metadata": {},
   "source": [
    "There are 327 duplicates in the academies outputs, and 346 in the maintained (excluding federations)\n",
    "\n",
    "\n",
    "academy_ar has 10444 entries, 148 of the urns in this list are duplicated, though they look to be schools which have changed from SAT to MAT\n",
    "\n",
    "The academies_list containes duplicated LAEstabs due to schools transitioning between SAT / MAT etc.\n",
    "\n",
    "maintained_schools has 10650 entries, 347 of which are nulls. These can just be dropped\n",
    "\n",
    "There are a few duplicates in federation data as well:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
