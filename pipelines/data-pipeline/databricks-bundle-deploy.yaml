trigger:
  branches:
    include:
      - main
      - develop
      - feature/databricks-notebooks

pool:
  vmImage: 'ubuntu-latest'

variables:
  - group: databricks-vars
  - name: PYTHON_VERSION
    value: '3.12'

stages:
  - stage: Validate
    displayName: 'Validate and Test'
    jobs:
      - job: ValidateAndTest
        displayName: 'Validate Bundle and Run Tests'
        steps:
          - task: UsePythonVersion@0
            inputs:
              versionSpec: '$(PYTHON_VERSION)'
            displayName: 'Use Python $(PYTHON_VERSION)'

          - script: |
              sudo apt-get update
              sudo apt-get install temurin-17-jdk
              export JAVA_HOME=$(/usr/libexec/java_home -v 17)
              export PATH="$JAVA_HOME/bin:$PATH"
            displayName: 'Install Java 17'

          - script: |
              curl -LsSf https://astral.sh/uv/install.sh | sh
              echo "##vso[task.prependpath]$HOME/.cargo/bin"
            displayName: 'Install uv'

          - script: |
              uv sync
            workingDirectory: $(System.DefaultWorkingDirectory)/databricks/education_benchmarking_and_insights
            displayName: 'Install Dependencies with uv'

          - script: |
              uv run pytest -v
            workingDirectory: $(System.DefaultWorkingDirectory)/databricks/education_benchmarking_and_insights
            displayName: 'Run unit tests'
            continueOnError: false

          - script: |
              curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
            workingDirectory: $(System.DefaultWorkingDirectory)/databricks/education_benchmarking_and_insights
            displayName: 'Install Databricks CLI'

          - script: |
              databricks bundle validate
            workingDirectory: $(System.DefaultWorkingDirectory)/databricks/education_benchmarking_and_insights
            displayName: 'Validate Bundle Configuration'
            env:
              DATABRICKS_HOST: $(DATABRICKS_HOST)
              DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

  - stage: DeployDev
    displayName: 'Deploy to Dev'
    dependsOn: Validate
    condition: and(succeeded(), in(variables['Build.SourceBranch'], 'refs/heads/develop', 'refs/heads/main'))
    jobs:
      - deployment: DeployDevBundle
        displayName: 'Deploy to Dev Environment'
        environment: 'development'
        strategy:
          runOnce:
            deploy:
              steps:
                - checkout: self

                - task: UsePythonVersion@0
                  inputs:
                    versionSpec: '$(PYTHON_VERSION)'
                  displayName: 'Use Python $(PYTHON_VERSION)'

                - script: |
                    curl -LsSf https://astral.sh/uv/install.sh | sh
                    echo "##vso[task.prependpath]$HOME/.cargo/bin"
                  displayName: 'Install uv'

                - script: |
                    uv sync
                  displayName: 'Install Dependencies with uv'

                - script: |
                    python -m pip install databricks-cli
                  displayName: 'Install Databricks CLI'

                - script: |
                    databricks bundle deploy --target dev
                  displayName: 'Deploy Bundle to Dev'
                  env:
                    DATABRICKS_HOST: $(DATABRICKS_HOST)
                    DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

                - script: |
                    echo "Bundle deployed successfully to dev"
                    databricks bundle summary --target dev
                  displayName: 'Deployment Summary'
                  env:
                    DATABRICKS_HOST: $(DATABRICKS_HOST)
                    DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

  - stage: DeployProd
    displayName: 'Deploy to Production'
    dependsOn: DeployDev
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    jobs:
      - deployment: DeployProdBundle
        displayName: 'Deploy to Production Environment'
        environment: 'development'
        strategy:
          runOnce:
            deploy:
              steps:
                - checkout: self

                - task: UsePythonVersion@0
                  inputs:
                    versionSpec: '$(PYTHON_VERSION)'
                  displayName: 'Use Python $(PYTHON_VERSION)'

                - script: |
                    curl -LsSf https://astral.sh/uv/install.sh | sh
                    echo "##vso[task.prependpath]$HOME/.cargo/bin"
                  displayName: 'Install uv'

                - script: |
                    uv sync
                  displayName: 'Install Dependencies with uv'

                - script: |
                    python -m pip install databricks-cli
                  displayName: 'Install Databricks CLI'

                - script: |
                    databricks bundle deploy --target prod
                  displayName: 'Deploy Bundle to Production'
                  env:
                    DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)

                - script: |
                    echo "Bundle deployed successfully to production"
                    databricks bundle summary --target prod
                  displayName: 'Deployment Summary'
                  env:
                    DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)