# Metric: [Metric Name Here]

> ğŸ“Œ How to Use This Template
>
> **Goal:**  
> This template is designed to ensure every metric we track is **meaningful** and **actionable**, not just â€œinteresting.â€  
> A metric is meaningful if it supports a clear purpose and can drive a decision or action.
>
> **Guidelines:**
>
> 1. **Always include:**
     >    - **Purpose** â€“ Why we track this metric, and what we aim to achieve or learn.
>    - **Actionability** â€“ The decision or action that will follow from changes in the metric.
> 2. **Include these only if the metric is a *User Insight* metric:**
     >    - **Assumption** â€“ The user behaviour or performance belief this metric will help validate.
>    - **Hypothesis / Test** â€“ The statement we are testing or insight we want to confirm/refute.
> 3. **Optional sections:**
     >    - **Target / Threshold** â€“ Add if the metric has a clear performance or quality target.
>    - **Reporting Frequency** â€“ Add if the metric has a defined review cadence.
>    - **Notes / Links** â€“ Add for references, dashboards, or historical context.
> 4. **Delete all blockquotes and any sections that do not apply** â€” keep the document concise and relevant.
>
> **Reminder:**  
> If a metric canâ€™t lead to a decision or action, it should not be added.

**Category:** Operational / User Insight / Both  
**Data Source:** [System, dashboard, or log source]  

**Purpose:**
>What are we hoping to learn or achieve by tracking this measure?  
*Example:* â€œEnsure the service meets SLA requirements and provides a fast, reliable experience.â€

**Actionability:**
>What decision could we make, or what action could we take, based on what we learn?  
*Example:* â€œIf the metric drops below threshold, trigger an automated scaling policy.â€

**Assumption:**
>What are we assuming about user behaviour or system performance that this measure will help us validate?  
*Example:* â€œUsers will abandon requests if the load time exceeds 2 seconds.â€

**Hypothesis / Test:**
>What specific hypothesis are we testing, or what insight are we trying to confirm or refute?  
*Example:* â€œReducing load time from 3s to 1.5s will increase conversion by 5%.â€

**Target / Threshold:**
>Define success criteria or limits.  
*Example:* â€œMaintain < 300ms average response time at 95th percentile.â€

**Reporting Frequency:**
>How often will this metric be measured and reviewed?  
*Example:* â€œReal-time dashboard, weekly review in Ops stand-up.â€

**Notes / Links:**
>Additional info, related dashboards, or historical data.  
*Example:* â€œDashboard: [link] | Status page: [link]â€

<!-- Leave the rest of this page blank -->
\newpage
