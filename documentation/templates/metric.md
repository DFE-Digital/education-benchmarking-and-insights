# Metric: [Metric Name Here]

> 📌 How to Use This Template
>
> **Goal:**  
> This template is designed to ensure every metric we track is **meaningful** and **actionable**, not just “interesting.”  
> A metric is meaningful if it supports a clear purpose and can drive a decision or action.
>
> **Guidelines:**
>
> 1. **Always include:**
     >    - **Purpose** – Why we track this metric, and what we aim to achieve or learn.
>    - **Actionability** – The decision or action that will follow from changes in the metric.
> 2. **Include these only if the metric is a *User Insight* metric:**
     >    - **Assumption** – The user behaviour or performance belief this metric will help validate.
>    - **Hypothesis / Test** – The statement we are testing or insight we want to confirm/refute.
> 3. **Optional sections:**
     >    - **Target / Threshold** – Add if the metric has a clear performance or quality target.
>    - **Reporting Frequency** – Add if the metric has a defined review cadence.
>    - **Notes / Links** – Add for references, dashboards, or historical context.
> 4. **Delete all blockquotes and any sections that do not apply** — keep the document concise and relevant.
>
> **Reminder:**  
> If a metric can’t lead to a decision or action, it should not be added.

**Category:** Operational / User Insight / Both  
**Data Source:** [System, dashboard, or log source]  

**Purpose:**
>What are we hoping to learn or achieve by tracking this measure?  
*Example:* “Ensure the service meets SLA requirements and provides a fast, reliable experience.”

**Actionability:**
>What decision could we make, or what action could we take, based on what we learn?  
*Example:* “If the metric drops below threshold, trigger an automated scaling policy.”

**Assumption:**
>What are we assuming about user behaviour or system performance that this measure will help us validate?  
*Example:* “Users will abandon requests if the load time exceeds 2 seconds.”

**Hypothesis / Test:**
>What specific hypothesis are we testing, or what insight are we trying to confirm or refute?  
*Example:* “Reducing load time from 3s to 1.5s will increase conversion by 5%.”

**Target / Threshold:**
>Define success criteria or limits.  
*Example:* “Maintain < 300ms average response time at 95th percentile.”

**Reporting Frequency:**
>How often will this metric be measured and reviewed?  
*Example:* “Real-time dashboard, weekly review in Ops stand-up.”

**Notes / Links:**
>Additional info, related dashboards, or historical data.  
*Example:* “Dashboard: [link] | Status page: [link]”

<!-- Leave the rest of this page blank -->
\newpage
